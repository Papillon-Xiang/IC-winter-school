{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-based Brain Tumour Segmentation Network\n",
    "## Import packages\n",
    "Please make sure you have all the required packages installed. If GPU is available, but you want to use CPU to train your model, make sure you add \" os.environ['CUDA_VISIBLE_DEVICES'] = '-1'.\n",
    "Package 'SimpleITK' is for loading the MR images, so you need to install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise MRI Volume Slices and Segmentation Maps\n",
    "Each MRI image contains information about a three-dimensional (3D) volume of space. An MRI image is composed of a number of voxels, which is like pixels in 2D images. Here we visualise the transverse plane (usually has a higher resolution) of some of the volumes and the corresponding segmentation maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(x,n=10):\n",
    "    i = n\n",
    "    j = 2\n",
    "    plt.figure(figsize=(15,20))\n",
    "    k = 1\n",
    "    idx_nums = np.random.randint(len(x),size=n)\n",
    "    for idx in idx_nums:\n",
    "        plt.subplot(i,j,k)\n",
    "        while k%2 != 0:\n",
    "            plt.imshow(np.load(x[idx])[:,:,0], cmap='gray')\n",
    "            plt.xlabel(\"Input\")\n",
    "            k += 1\n",
    "        plt.subplot(i,j,k)\n",
    "        plt.imshow(np.load(x[idx].split('_')[0]+'_seg.npy')[:,:], cmap='gray')\n",
    "        plt.xlabel(\"Ground Truth\")\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "img_path = 'Dataset/'\n",
    "img_list = []\n",
    "CLASS = 'Yes'\n",
    "all_files = os.listdir(img_path + CLASS)\n",
    "files = [item for item in all_files if \"img\" in item]\n",
    "random.shuffle(files)\n",
    "img_num = len(files)\n",
    "for (n, file_name) in enumerate(files):\n",
    "    img = os.path.join(img_path,CLASS,file_name)\n",
    "    seg = os.path.join(img_path,CLASS,file_name.split('_')[0]+'_seg.npy')\n",
    "    img_list.append(img)\n",
    "plot_samples(img_list, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing (Optional)\n",
    "\n",
    "Images in the original dataset are usually in different sizes, so sometimes we need to resize and normalise (z-score is commonly used in preprocessing the MRI images) them to fit the CNN model. Depending on the images you choose to use for training your model, some other preprocessing methods. If preprocessing methods like cropping is applied, remember to convert the segmentation result back to its original size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir Train Val /s /q\n",
    "!md Train Val Train\\Yes Train\\No Val\\Yes Val\\No\n",
    "\n",
    "\n",
    "img_path = 'Dataset/'\n",
    "train_list = []\n",
    "val_list = []\n",
    "for CLASS in os.listdir(img_path):\n",
    "    if not CLASS.startswith('.'):\n",
    "        all_files = os.listdir(img_path + CLASS)\n",
    "        files = [item for item in all_files if \"img\" in item]\n",
    "        random.shuffle(files)\n",
    "        img_num = len(files)\n",
    "        for (n, file_name) in enumerate(files):\n",
    "            img = os.path.join(img_path,CLASS,file_name)\n",
    "            seg = os.path.join(img_path,CLASS,file_name.split('_')[0]+'_seg.npy')\n",
    "            # 80% of images will be used for training, change the number here \n",
    "            # to use different number of images for training your model.\n",
    "            if n < 0.8*img_num:\n",
    "                shutil.copy(img, os.path.join('Train/',CLASS,file_name))\n",
    "                train_list.append(os.path.join('Train/',CLASS,file_name))\n",
    "                shutil.copy(seg, os.path.join('Train/',CLASS,file_name.split('_')[0]+'_seg.npy'))\n",
    "            else:\n",
    "                shutil.copy(img, os.path.join('Val/',CLASS,file_name))\n",
    "                val_list.append(os.path.join('Val/',CLASS,file_name))\n",
    "                shutil.copy(seg, os.path.join('Val/',CLASS,file_name.split('_')[0]+'_seg.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-time data augmentation\n",
    "Generalizability is crucial to a deep learning model and it refers to the performance difference of a model when evaluated on the seen data (training data) versus the unseen data (testing data). Improving the generalizability of these models has always been a difficult challenge. \n",
    "\n",
    "**Data Augmentation** is an effective way of improving the generalizability, because the augmented data will represent a more comprehensive set of possible data samples and minimizing the distance between the training and validation/testing sets.\n",
    "\n",
    "There are many data augmentation methods you can choose in this projects including rotation, shifting, flipping, etc.\n",
    "\n",
    "You are encouraged to try different augmentation method to get the best segmentation result.\n",
    "\n",
    "\n",
    "## Get the data generator ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=4, dim=(240,240), n_channels=3, flips=(0.2,0.2), rotates=(0.1,0.2,0.1),\n",
    "                 augmentation=False, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.flips = flips\n",
    "        self.rotates = rotates\n",
    "        self.augmentation = augmentation\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        if self.augmentation:\n",
    "            X, y = self.__data_augmentation(list_IDs_temp)\n",
    "        else:\n",
    "            X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim, 1))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            # Add data augmentation here\n",
    "            X[i,] = np.load(ID)\n",
    "\n",
    "            # Store class\n",
    "            seg = np.zeros((*self.dim, 1))\n",
    "            seg_0 = np.expand_dims(np.load(ID.split('_')[0]+'_seg.npy'), axis = 2)\n",
    "            y[i] = np.maximum(seg, seg_0)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __data_augmentation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim, 1))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            # Add data augmentation here\n",
    "\n",
    "            X_temp = np.load(ID)\n",
    "\n",
    "            # Store class\n",
    "            seg = np.zeros((*self.dim, 1))\n",
    "            seg_0 = np.expand_dims(np.load(ID.split('_')[0]+'_seg.npy'), axis = 2)\n",
    "            y_temp = np.maximum(seg, seg_0)\n",
    "            \n",
    "            for a in np.arange(2):\n",
    "                if np.random.binomial(1, self.flips[a]):\n",
    "                    X_temp = np.flip(X_temp, axis = a)\n",
    "                    y_temp = np.flip(y_temp, axis = a)\n",
    "                    \n",
    "            a = np.random.choice(np.arange(4), p=np.insert(self.rotates, 0, 1-np.sum(self.rotates)))\n",
    "            X_temp = np.rot90(X_temp, k = a)\n",
    "            y_temp = np.rot90(y_temp, k = a)\n",
    "\n",
    "            X[i,] = X_temp\n",
    "            y[i] = y_temp\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(240,240), n_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index:index+1]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def get_item_id(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index:index+1]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return list_IDs_temp, X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((1, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load(ID)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a metric for the performance of the model\n",
    "Dice score is used here to evaluate the performance of your model.\n",
    "More details about the Dice score and other metrics can be found at \n",
    "https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2. Dice score can be also used as the loss function for training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-2):\n",
    "    y_true_cal = K.cast_to_floatx(y_true)\n",
    "    y_pred_cal = K.cast_to_floatx(y_pred > 0.5)\n",
    "    intersection = K.sum(y_true_cal * y_pred_cal, axis=[1,2,3])\n",
    "    union = K.sum(y_true_cal, axis=[1,2,3]) + K.sum(y_pred_cal, axis=[1,2,3])\n",
    "    dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own model here\n",
    "The U-Net (https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) structure is widely used for the medical image segmentation task. You can build your own model or modify the UNet by changing the hyperparameters for our task. If you choose to use Keras, more information about the Keras layers including Conv2D, MaxPooling and Dropout can be found at https://keras.io/api/layers/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(28)\n",
    "# input image tile\n",
    "def InputBlock(input, filters, kernel_size=3, padding='same'):\n",
    "    convolution_1 = Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, kernel_initializer = 'he_normal', \n",
    "                                    activation='relu')(input)\n",
    "    convolution_1 = BatchNormalization()(convolution_1)\n",
    "    convolution_2 = Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, kernel_initializer = 'he_normal',\n",
    "                                    activation='relu')(convolution_1)\n",
    "    convolution_2 = BatchNormalization()(convolution_2)\n",
    "    return convolution_2\n",
    "\n",
    "# contracting path\n",
    "def ContractingPathBlock(input, filters, kernel_size=3, padding='same'):\n",
    "    down_sampling = MaxPool2D((2, 2))(input)\n",
    "    convolution_1 = Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, kernel_initializer = 'he_normal',\n",
    "                                    activation='relu')(down_sampling)\n",
    "    convolution_1 = BatchNormalization()(convolution_1)\n",
    "    convolution_2 = Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, kernel_initializer = 'he_normal',\n",
    "                                    activation='relu')(convolution_1)\n",
    "    convolution_2 = BatchNormalization()(convolution_2)\n",
    "    return convolution_2\n",
    "\n",
    "# expansive path\n",
    "def ExpansivePathBlock(input, con_feature, filters, tran_filters, kernel_size=3, tran_kernel_size=2, strides=1,\n",
    "                       tran_strides=2, padding='same', tran_padding='same'):\n",
    "    upsampling = Conv2DTranspose(filters=tran_filters, kernel_size=tran_kernel_size,\n",
    "                                                 strides=tran_strides, padding=tran_padding)(input)\n",
    "    concat_feature = tf.image.resize(con_feature, ((upsampling.shape)[1], (upsampling.shape)[2]),\n",
    "                                  method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    concatenation_feature = tf.concat([concat_feature, upsampling], axis=3)\n",
    "    convolution_1 = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer = 'he_normal',\n",
    "                                    activation='relu')(concatenation_feature)\n",
    "    convolution_1 = BatchNormalization()(convolution_1)\n",
    "    convolution_2 = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer = 'he_normal',\n",
    "                                    activation='relu')(convolution_1)\n",
    "    convolution_2 = BatchNormalization()(convolution_2)\n",
    "    return convolution_2\n",
    "\n",
    "# U-Net\n",
    "def UNet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # input block\n",
    "    input_block = InputBlock(inputs, 64)\n",
    "\n",
    "    # contracting path\n",
    "    convolution_1 = ContractingPathBlock(input_block, 128)\n",
    "    convolution_2 = ContractingPathBlock(convolution_1, 256)\n",
    "    convolution_3 = ContractingPathBlock(convolution_2, 512)\n",
    "    convolution_4 = ContractingPathBlock(convolution_3, 1024)\n",
    "    convolution_4 = Dropout(rate = 0.5)(convolution_4)\n",
    "\n",
    "    # expansive path\n",
    "    expand_4 = ExpansivePathBlock(convolution_4, convolution_3, 512, 512)\n",
    "    expand_3 = ExpansivePathBlock(expand_4, convolution_2, 256, 256)\n",
    "    expand_2 = ExpansivePathBlock(expand_3, convolution_1, 128, 128)\n",
    "    expand_1 = ExpansivePathBlock(expand_2, input_block, 64, 64)\n",
    "\n",
    "    convolution_5 = Conv2D(2, 1, activation='relu', padding='same', kernel_initializer='he_normal')(expand_1)\n",
    "    outputs = Conv2D(1, 1, activation = 'sigmoid')(convolution_5)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model = UNet(input_shape=(240, 240, 3))\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=dice_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model here\n",
    "Once you defined the model and data generator, you can start training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(train_list, augmentation=True)\n",
    "val_generator = DataGenerator(val_list)\n",
    "earlystopping = EarlyStopping(monitor='val_dice_coef', mode='max', patience=5)\n",
    "results = model.fit(train_generator, validation_data=val_generator, epochs=30, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "Once your model is trained, remember to save it for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_segmentation_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model on the test set\n",
    "After your last Q&A session, you will be given the test set. Run your model on the test set to get the segmentation results and submit your results in a .zip file. If the MRI image is named '100_img.npy', save your segmentation result as '100_seg.npy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'Val/'\n",
    "output_dir = 'Output/'\n",
    "#load your model here\n",
    "model_load = load_model('trained_segmentation_model.h5', custom_objects={'dice_coef':dice_coef})\n",
    "test_list = []\n",
    "for CLASS in os.listdir(test_dir):\n",
    "    if not CLASS.startswith('.'):\n",
    "        all_files = os.listdir(test_dir + CLASS)\n",
    "        files = [item for item in all_files if \"img\" in item]\n",
    "        for file_name in files:\n",
    "            test_list.append(test_dir + CLASS + '/' + file_name)\n",
    "test_generator = TestGenerator(test_list)\n",
    "\n",
    "predictions = []\n",
    "for i in range(test_generator.__len__()):\n",
    "    ID, x_test = test_generator.get_item_id(i)\n",
    "    prediction = model_load.predict(np.array(x_test))\n",
    "    predictions.append(prediction[0])\n",
    "    str_1 = ID[0].split('_')[0]\n",
    "    str_2 = str_1.split('/')[2]\n",
    "    result=np.reshape(np.uint8(prediction[0]>0.5), (240, 240))\n",
    "    np.save(output_dir+str_2+'_seg.npy', result)\n",
    "accuracy = dice_coef(np.array(y_test), np.array(predictions))\n",
    "print('Test Accuracy = %.5f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
